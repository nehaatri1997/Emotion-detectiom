# -*- coding: utf-8 -*-
"""Emotion detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yd5pF7bTeqUADNOTkXxsQ9HQFeC2hrfK
"""

pip install transformers torch

from transformers import pipeline

# Initialize the emotion classification pipeline
emotion_classifier = pipeline("text-classification", model="j-hartmann/emotion-english-distilroberta-base", return_all_scores=True)

# Sample texts to analyze
texts = [
    "I am so happy today!",
    "I feel really sad about what happened.",
    "I'm furious at the situation!",
    "I'm surprised and excited about the news!"
]

# Detect emotions in each text
for text in texts:
    result = emotion_classifier(text)
    print(f"Text: {text}")
    for emotion in result[0]:
        print(f"{emotion['label']}: {emotion['score']:.3f}")
    print("\n")

# prompt: how to check the expressions with camera on?

from transformers import pipeline
!pip install transformers torch opencv-python

import cv2
from google.colab.patches import cv2_imshow

# Initialize the emotion classification pipeline
emotion_classifier = pipeline("text-classification", model="j-hartmann/emotion-english-distilroberta-base", return_all_scores=True)

# Sample texts to analyze
texts = [
    "I am so happy today!",
    "I feel really sad about what happened.",
    "I'm furious at the situation!",
    "I'm surprised and excited about the news!"
]

# Function to capture a frame from the camera and analyze text
def capture_and_analyze():
    try:
        camera = cv2.VideoCapture(0)  # 0 for default camera
        if not camera.isOpened():
            print("Error: Could not open camera.")
            return

        ret, frame = camera.read()
        if not ret:
            print("Error: Could not capture frame.")
            camera.release()
            return

        # Display the captured frame (Optional)
        #cv2_imshow(frame)

        # Analyze the text
        for text in texts:
            result = emotion_classifier(text)
            print(f"Text: {text}")
            for emotion in result[0]:
                print(f"{emotion['label']}: {emotion['score']:.3f}")
            print("\n")

        camera.release()
    except Exception as e:
        print(f"An error occurred: {e}")

# Call the function to capture and analyze
capture_and_analyze()